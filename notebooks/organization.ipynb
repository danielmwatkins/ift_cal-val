{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abb632d-2720-4c8e-adc1-490d6af81c56",
   "metadata": {},
   "source": [
    "# Organization\n",
    "Cells in this notebook are used to move files around and rename objects.\n",
    "\n",
    "## Copy MODIS imagery from the IFT Resources folder\n",
    "The IFT-Pipeline downloads the truecolor and falsecolor MODIS imagery as well as the landmask. This script moves the files to the folder `data/modis/` and names them using the case number, region, size, date, and satellite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854be335-f139-4103-a91a-168576983342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "regions_to_transfer = []\n",
    "for region in regions_to_transfer:\n",
    "    dataloc = '../data/ift_resources/' + region + '/'\n",
    "    saveloc = '../data/modis/'\n",
    "    case_folders = [f for f in os.listdir(dataloc) if '.DS_Store' not in f]\n",
    "    \n",
    "    for case in case_folders:\n",
    "        cn, region, dx, start, end = case.split('-')\n",
    "        for satellite in ['aqua', 'terra']:\n",
    "            for imtype in ['falsecolor', 'truecolor']:\n",
    "                old_path = '.'.join([dataloc + case + '/' + imtype + '/' + start, satellite, imtype, '250m', 'tiff'])\n",
    "                new_path = saveloc + imtype + '/' + '.'.join(['-'.join([cn, region, dx, start]),\n",
    "                                                              satellite, imtype, '250m', 'tiff'])\n",
    "        \n",
    "                ! mv $old_path $new_path\n",
    "        # same thing for landmask\n",
    "        old_path = dataloc + case + '/landmask.tiff'\n",
    "        new_path = saveloc + 'landmask/' + '-'.join([cn, region, dx, 'landmask.tiff'])\n",
    "        ! mv $old_path $new_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a3d4a-a2eb-4944-92f8-54043b5eb1e3",
   "metadata": {},
   "source": [
    "## Copy MODIS cloud fraction data from the ebseg output\n",
    "The ebseg algorithm downloads cloud fraction snapshots for each satellite. We will use these to validate the cloud masks and for the comparison between the two algorithm types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fba2585b-9928-4caf-a9ab-6f78d6bf9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "regions = pd.read_csv('../data/metadata/region_definitions.csv', index_col='region')\n",
    "cases = pd.read_csv('../data/metadata/validation_dataset_case_list.csv')\n",
    "cases['start_date'] = pd.to_datetime(cases['start_date'].values)\n",
    "dataloc = '../data/ift_data/ebseg_v0/'\n",
    "saveloc = '../data/modis/'\n",
    "\n",
    "for row, case in cases.iterrows():\n",
    "    cn = str(case.case_number).zfill(3)\n",
    "    region = case.region\n",
    "    start = case.start_date # check start date format\n",
    "    end = case.start_date + pd.to_timedelta('1d')\n",
    "    dx = '100km'\n",
    "    imtype = 'cloudfraction'\n",
    "    for satellite in ['aqua', 'terra']:\n",
    "        case_folder = '-'.join([cn, region, dx, start.strftime('%Y%m%d'), end.strftime('%Y%m%d')])\n",
    "        case_folder += '-256m/' + '-'.join([region, start.strftime('%Y-%m-%d'), satellite])\n",
    "        old_path = dataloc + region + '/' + case_folder + '/' + '_img-cloud.tiff'\n",
    "        new_path = saveloc + imtype + '/' + '.'.join(['-'.join([cn, region, dx, start.strftime('%Y%m%d')]),\n",
    "                                                      satellite, imtype, '250m', 'tiff'])\n",
    "        shutil.copy2(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae20f77-4933-49f4-9e58-d8d7b5e0c2f4",
   "metadata": {},
   "source": [
    "# Copy and rename labeled images from the ebseg output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb5c2364-e3f3-435c-998e-f52939cf8130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found for case 000 ( baffin_bay )\n",
      "File not found for case 082 ( barents_kara_seas )\n",
      "File not found for case 082 ( barents_kara_seas )\n",
      "File not found for case 089 ( barents_kara_seas )\n",
      "File not found for case 144 ( beaufort_sea )\n",
      "File not found for case 443 ( bering_strait )\n",
      "File not found for case 443 ( bering_strait )\n",
      "File not found for case 163 ( bering_strait )\n",
      "File not found for case 163 ( bering_strait )\n",
      "File not found for case 450 ( bering_strait )\n",
      "File not found for case 450 ( bering_strait )\n",
      "File not found for case 168 ( bering_strait )\n",
      "File not found for case 168 ( bering_strait )\n",
      "File not found for case 170 ( bering_strait )\n",
      "File not found for case 171 ( bering_strait )\n",
      "File not found for case 200 ( chukchi_east_siberian_seas )\n",
      "File not found for case 446 ( chukchi_east_siberian_seas )\n",
      "File not found for case 226 ( chukchi_east_siberian_seas )\n",
      "File not found for case 226 ( chukchi_east_siberian_seas )\n",
      "File not found for case 234 ( chukchi_east_siberian_seas )\n",
      "File not found for case 240 ( chukchi_east_siberian_seas )\n",
      "File not found for case 240 ( chukchi_east_siberian_seas )\n",
      "File not found for case 241 ( chukchi_east_siberian_seas )\n",
      "File not found for case 241 ( chukchi_east_siberian_seas )\n",
      "File not found for case 244 ( chukchi_east_siberian_seas )\n",
      "File not found for case 244 ( chukchi_east_siberian_seas )\n",
      "File not found for case 256 ( greenland_sea )\n",
      "File not found for case 276 ( greenland_sea )\n",
      "File not found for case 311 ( hudson_bay )\n",
      "File not found for case 311 ( hudson_bay )\n",
      "File not found for case 320 ( hudson_bay )\n",
      "File not found for case 455 ( hudson_bay )\n",
      "File not found for case 452 ( hudson_bay )\n",
      "File not found for case 452 ( hudson_bay )\n",
      "File not found for case 352 ( laptev_sea )\n",
      "File not found for case 352 ( laptev_sea )\n",
      "File not found for case 363 ( laptev_sea )\n",
      "File not found for case 372 ( laptev_sea )\n",
      "File not found for case 378 ( laptev_sea )\n",
      "File not found for case 378 ( laptev_sea )\n",
      "File not found for case 386 ( laptev_sea )\n",
      "File not found for case 386 ( laptev_sea )\n",
      "File not found for case 387 ( laptev_sea )\n",
      "File not found for case 466 ( sea_of_okhostk )\n",
      "File not found for case 401 ( sea_of_okhostk )\n",
      "File not found for case 457 ( sea_of_okhostk )\n",
      "File not found for case 457 ( sea_of_okhostk )\n",
      "File not found for case 464 ( sea_of_okhostk )\n",
      "File not found for case 464 ( sea_of_okhostk )\n",
      "File not found for case 461 ( sea_of_okhostk )\n",
      "File not found for case 431 ( sea_of_okhostk )\n",
      "File not found for case 431 ( sea_of_okhostk )\n",
      "File not found for case 440 ( sea_of_okhostk )\n",
      "File not found for case 440 ( sea_of_okhostk )\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "regions = pd.read_csv('../data/metadata/region_definitions.csv', index_col='region')\n",
    "cases = pd.read_csv('../data/metadata/validation_dataset_case_list.csv')\n",
    "cases['start_date'] = pd.to_datetime(cases['start_date'].values)\n",
    "dataloc = '../data/ift_data/ebseg_v0/'\n",
    "saveloc = '../data/ift_images/ebseg_v0/'\n",
    "\n",
    "for row, case in cases.iterrows():\n",
    "    cn = str(case.case_number).zfill(3)\n",
    "    region = case.region\n",
    "    start = case.start_date # check start date format\n",
    "    end = case.start_date + pd.to_timedelta('1d')\n",
    "    dx = '100km'\n",
    "    imtype = 'ebseg_v0'\n",
    "    for satellite in ['aqua', 'terra']:\n",
    "        case_folder = '-'.join([cn, region, dx, start.strftime('%Y%m%d'), end.strftime('%Y%m%d')])\n",
    "        case_folder += '-256m/' + '-'.join([region, start.strftime('%Y-%m-%d'), satellite])\n",
    "        old_path = dataloc + region + '/' + case_folder + '/' + 'final.tif'\n",
    "        new_path = saveloc + '-'.join([cn, region, dx, start.strftime('%Y%m%d'), satellite, imtype]) + '.tiff'\n",
    "        if os.path.isfile(old_path):\n",
    "            shutil.copyfile(old_path, new_path)\n",
    "        else:\n",
    "            print('File not found for case', cn, '(', region, ')')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcf4af-4731-4e8b-9b13-8aa441b56fc6",
   "metadata": {},
   "source": [
    "In cases where the full image is cloud-covered, the expected result is that no segmented image is produced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de90edd7-594b-4120-827a-d87954b7a4c5",
   "metadata": {},
   "source": [
    "# Rename labeled PNG files to use standardized convention\n",
    "Some manually labeled images had older versions of filenames. Updated version lets you split the filename to get the information.\n",
    "\n",
    "1. 379 missing aqua labeled landfast\n",
    "2. 0, 5, 7, 8, 16, 19, missing labeled landfast and landmask\n",
    "4. 008 missing terra labeled floes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc762b3-846d-4230-b08c-9f722aa805c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "regions = pd.read_csv('../data/metadata/region_definitions.csv', index_col='region')\n",
    "cases = pd.read_csv('../data/metadata/validation_dataset_case_list.csv')\n",
    "cases['start_date'] = pd.to_datetime(cases['start_date'].values)\n",
    "dataloc = '../data/validation_images/'\n",
    "\n",
    "for imtype in ['labeled_floes', 'labeled_landfast', 'landmask']:\n",
    "    for row, case in cases.iterrows():\n",
    "        cn = str(case.case_number).zfill(3)\n",
    "        region = case.region\n",
    "        start = case.start_date\n",
    "        for satellite in ['aqua', 'terra']:\n",
    "            if 'barents' in region:\n",
    "                old_path = dataloc + imtype + '_png/' + '_'.join([cn, 'barents-kara_seas', start.strftime('%Y%m%d'), satellite, imtype]) + '.png'\n",
    "            elif 'chukchi' in region:\n",
    "                old_path = dataloc + imtype + '_png/' + '_'.join([cn, 'chukchi-east_siberian_sea', start.strftime('%Y%m%d'), satellite, imtype]) + '.png'\n",
    "            else:\n",
    "                old_path = dataloc + imtype + '_png/' + '_'.join([cn, region, start.strftime('%Y%m%d'), satellite, imtype]) + '.png'\n",
    "            new_path = dataloc + imtype + '_png/' + '-'.join([cn, region, start.strftime('%Y%m%d'), satellite, imtype]) + '.png'\n",
    "            if os.path.isfile(old_path):\n",
    "                shutil.copyfile(old_path, new_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c627aa-38c3-4cc7-8837-3ed1ce2d12e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d75e04ed-5d4f-4d77-8718-4f2c27d467ed",
   "metadata": {},
   "source": [
    "# Merging validation tables and algorithmic metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a01c4b4c-aaed-411e-86dc-b480501d8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6e602b9d-7e9a-40c2-961d-f26a33b09620",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.read_csv('../data/metadata/validation_dataset_case_list.csv')\n",
    "cases['mean_sea_ice_concentration'] = cases['mean_sea_ice_concentration'].round(3)\n",
    "cases['case_number'] = [str(x).zfill(3) for x in cases['case_number']]\n",
    "\n",
    "vtables = []\n",
    "for file in os.listdir('../data/validation_tables/'):\n",
    "    if '.csv' in file:\n",
    "        vtables.append(pd.read_csv('../data/validation_tables/' + file))\n",
    "vtables = pd.concat(vtables)\n",
    "vtables['case_number'] = [str(x).zfill(3) for x in vtables['case_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c449addd-53d1-4342-8c58-25624484535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset_metadata = cases.merge(vtables, left_on=['case_number', 'region', 'start_date'], right_on=['case_number', 'region', 'start_date'], how='outer').drop('notes', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3083df2c-7c24-4caf-b413-8b65d4d818be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(validation_dataset_metadata.visible_floes == 'yes').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d434c7-a07c-4a95-bda1-1ef4e9d01b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
